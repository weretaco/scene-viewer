<!DOCTYPE html>
<!-- saved from url=(0069)http://graphics.cs.cmu.edu/courses/15-472-s24/A1/report-template.html -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>15-472-s24: A1 - Scene Graph</title>
<style>
/* feel free to style your report in a fancier way! */

@import url('https://fonts.googleapis.com/css2?family=Quicksand:wght@300;400;700&Anonymous+Pro&display=swap');

html {
	background:#505055;
}

body {
	font-family: 'Quicksand', sans-serif;
	color:#000;
	background:#eeeee8;
	font-size:15px;
	margin: 1em auto 50vh auto;
	padding: 1em 2em 1em 2em;
	max-width:45em;
	border-radius:4px;
	box-shadow:0 0 10px #0008;
}

h1 { font-size: 20px; font-weight: 700; }
h2 { font-size: 16px; font-weight: 700; }
h3 { font-size: 16px; font-weight: 400; }
h4 { font-size: 14px; font-weight: 400; }

h1, h2, h3, h4 {
	margin: 15px 0 0 -10px;
}

p {
	margin: 5px 0 0 0;
}

.subtitle {
	display:block;
	font-size:16px;
	font-weight:400;
}

.placeholder {
	color:#800;
	font-style:italic;
}

kbd {
	display:inline-block;
	background:#ccc;
	color:#444;
	font-style:normal;
	font-weight:700;
	border-radius:8px;
	padding:1px 6px;
	margin:1px;
	border:1.5px solid #aaa;
}

code {
	font-family: 'Anonymous Pro', monospace;
	background: #222;
	color:#fff;
	border-radius:4px;
	padding:2px 4px;
	margin:1px;
}

code var {
	color:#ef5;
	font-style:italic;
}

.atag {
	font-family: 'Calistoga', serif;
	font-size:90%;
	color:#000;
	background:#b00;

	display:inline-block;
	padding:1px 4px;
	border-radius: 4px;
	line-height:120%;
}
.atag:before {
	content:'Â»';
}
.atag.extra {
	background:#b08;
}
.atag.creative {
	/* thanks, shout.horse! */
	background:linear-gradient(0.4turn, #ffe680, #916f6f);
}

</style>
</head>
<body>
<h1>A1: Scene Viewer
<span class="subtitle">by <span class="placeholder">Dmitry Portnoy (dportnoy)</span></span>
</h1>

<p class="placeholder">

	I initially built the json parser and structures to store the scenegraph, which wre not dependent on the
the existing Vulkan starter code. The parser was fun to work on and is generic. It doesn't support some aspects
of json that don't occur in the s72 files, but it could easily be used as-is for other projects. After that, I
replaced the code to load the minimal set of geometry from the tutorial with code that loaded data from the s72 scene.
I kept the logic the same, nit had separate buffers for every mesh. Then, I started adding support for the differnt cli
flags. I made a somewhat genercic cli parser to handle them. I kept the same general code structure, but incorporated
the different features, such as culling, animation, and headless mode into it as seamlessly as I could. Since most of the
setup logic for regular execution and headless mode is the same, I ended up modifying many of the existing functions to
slightly change their behavior based on whether the app was running in headless mode.
	Unfortunately, I wasn't able to complete everything. I implemented the basic logic for frustum culling, but something
about my equations was wrong and visible objects were getting culled. I also did not implement the animation functionality
in headless mode. To do so, I'd have to rewrite how my existing code kept track of timing, but I ran out of time. I also
didn't have time to create my own animation or do much performance testing.

</p>

<h2>My Animation <span class="atag creative">A1-create</span></h2>

<p class="placeholder">
I did not have enough time to create an animation
</p>

<video>
</video>

<p class="placeholder">
Describe how you created your animation.
</p>

<h2>Using the Scene Viewer</h2>

<p class="placeholder">Provide a short overview of how to use your viewer.</p>

<h3>Command-line Arguments</h3>

<ul>
<li class="placeholder"><code>--scene <var>scene.s72</var></code> -- required -- load scene from <code><var>scene.s72</var></code></li>
<li class="placeholder"><code>--camera <var>name</var></code> -- optional -- render the scene from the specified camera's POV. Otherwise, a default orbit camera is used</li>
<li class="placeholder"><code>--physical-device <var>name</var></code> -- required -- uses the physical device whose VkPhysicalDeviceProperties::deviceName matches <var>name</var></li>
<li class="placeholder"><code>--list-physical-devices</code> -- optional -- lists all the physical devices on the system, any of which could be used with <code>--physical-device</code></li>
<li class="placeholder"><code>--drawing-size <var>w</var> <var>h</var></code> -- optional -- sets the initial size of the window to the specified dimensions. Otherwise, creates an 800x600 window</li>
<li class="placeholder"><code>--culling <var>none|frustum</var></code> -- optional -- specifies whether to enable AABB frustum culling. The default is none.</li>
<li class="placeholder"><code>--headless <var>events</var></code> -- optional -- will start in headless mode, reading timing events from the <var>events</var> file, and rendering some frames as PPM images</li>
</ul>

<h3>Controls</h3>

<ul>
<li class="placeholder"><kbd>LMB+Drag</kbd> orbit the camera.</li>
<li class="placeholder"><kbd>Z</kbd> switch switch between the different cameras in the scene</li>
</ul>


<h2>My Code</h2>

<p class="placeholder">
For each of the following sections, describe the overall structure of your code, and reference the specific files/functions/data structures that you used.
For any parts that are incomplete, discuss what you were able to do and what you tried but couldn't get working.
</p>

<p class="placeholder">
The purpose of this section is to get you to think critically about your code by explaining it to course staff; these thoughts may help you improve the code as you work on it in A2 and beyond.
This section also forms a road map to your code that we can use while grading.
</p>

<h3>Support Code for Math and Vulkan</h3>

<p class="placeholder">
I ran out of time to write my own math library, but instead used glm. However, if I had done so, I would have probably started
implementing the vectors as C++ vectors and written general functions for operations like addition, cross product, dot product,
and normalizing vectors. Doing this for matrices would not be as straughtforward, but I'd potentially just focus on 4x4 matrices.

Regarding my Vulkan code, I mostly kept the same structure as the tutorial, but I tried to keept very similar entities, such as
images and images together and similarly named. If I were to refactor the code more, I'd probably create structs to more explcitly
group them and let their lifecycles be managed more easily. For getting a window, I had a generic window class that called system-specific window logic under the hood, basically like
GLFW does. I worked mostly in Linux, so I had a linux-specific window implementation, and a GLFW "implementation" that was msotly a
passthrough to GLFW functions, but that I could use to test my Linux-specific implementation with. I kept the swapchain logic mostly
the same as the tutorial, but I did generalize the concept somewhat so that any set of images could potentially act as the swapchain.

<h3>Loading scenes, Mesh data <span class="atag">A1-load</span></h3> 

<p class="placeholder">

	I built a generic, although somewhat limited, JSON parser first. It doesn't handle cases that don't occur in the scene files, like
loading booleans, and escape sequences in strings. I parsed parsed the JSON into tokens. A token was usually one character, but could
contain multiple. For instance, a colon, open curly brace, or close square bracket, would all be tokens. However, a multi-digit number
or a string would also be one token. Once the file was "grouped" into tokens, I parsed those tokens into higher-level JSON entities:
objects, arrays, strings, and numbers, in a tree-like strucutre stemming from the root object. After that, I took this generic JSON
representation and parsed it into scene elements, relying on the known structure of s72 files. For instance, I could assume the
top-level element was an array, and its children fell into a small group of well-defined types.
	I stored the scengraph in mostly the same way as the json. However, I remapped the indicies and stored objects of each type (i.e.,
nodes, cameras, etc) in different arrays. When initially reading in the objects, I mapped their "global" indicies to indecies into the
array of their type. This restructuring made it easier to, for instance, loop through only the meshes, for when I render them, or only
the cameras, when I want to let the user cycle through them. The mesh vertex data is loaded from the b72 files and saved as arrays along
with the other data on the respective Mesh object.
</p>

<h3>Drawing the scene. <span class="atag">A1-show</span></h3>

<p class="placeholder">
	Since my scene is already organized in a tree-like structure with parent nodes containing child indicies, I just do an in-order traversal of the tree,
such that each child multiplies it's own model matrix by that of its parent. When I encounter a mesh in the traversal, I make a draw call to render it,
using the combined model matrix, along with the projection and view patrices. Once I have the correct model matrix, I also do the frustum culling check,
although that doesn't currently function correctly.
	I send the vertex data for each mesh in a separate buffer. The projection and view matrices I send in a uniform buffer once per frame, and the model
matrices I send using a push constant that I update with each draw call. It would be more efficient to create an array of model matrices in a uniform buffer
and send indicies into that array as vertex data, in which case I could potentially draw all the objects for a frame in one call.
</p>
<p class="placeholder">
Include a screenshot of your viewer drawing an example scene.
</p>

<h3>Handling interactive camera and debug camera movement. <span class="atag">A1-show</span></h3>

<p class="placeholder">
Cover, at least:
what camera controls you decided to implement;
where the camera controls are implemented.
</p>
<p class="placeholder">
Include a screen recording of you moving the camera in a scene.
</p>

<h3>Frustum culling <span class="atag">A1-cull</span></h3>

<p class="placeholder">

I implemented AABB frustum culling and stored each AABB as a pair of points, a min and a max. The AABB itself is only computed when the mesh is loaded,
but it's transformed by the corresponding object's model matrix every frame. I update all the matrices for that frame, then compare each AABB
with the 6 bounding planes of the frustum, then render the corresponding object, assuming it wasn't culled. However, something is wrong with my
intersection test, and objects that should be rendered are often culled

</p>
<p class="placeholder">
Include a screenshot or recording showing that culling is working (e.g., by using a debug camera to show that meshes outside the user camera's view aren't being drawn).
</p>

<h3>Animating the scene <span class="atag">A1-move</span></h3>

<p class="placeholder">
	My viewer stores keyframes by loading them into an array of times and an array of values, just like they're stored in the scene file.
My code has an update loop that gets the current time, and I also have the current frame for each animation. I compare that time
to the time of the current frame and the next frame, to see if it's time to switch to the next frame (i.e. when the current time
is equal to or greater than the time of the next animation). Then, I interpolate to get the correct current value based on the current
time and the times of the two keyframes.
	I currently don't have animations working correctly in headless mode, but the main thing I am missing is for each animation to keep
track of its own start time as opposed to using a common start time for all animations. If I did that, I could pretty easily use my
existing system to play animations in headless mode, and potentially at different speeds, just by multiplying all the keyframe times
by a factor.
</p>

<p class="placeholder">
Include a screen recording showing an animation being played back by your viewer.
</p>

<h3>Handling headless mode <span class="atag">A1-hide</span></h3>

<p class="placeholder">
	The major thing the window provided was the swap chain. Since the swap chain is basically just a
set of images, I decided to simulate a 3-image swapchain, created 3 in-memory images, and rotated
through them for each frame, to simulate the logic flow of requesting images from an actual swap chain.
Since I didn't have a window to get a width and height from, I relied on the --drawing-size CLI arguments.
	I handled the retrieving timestamps from the events file by reading them sequentially and returning
them to the renderer instead of actual clock time. I'd render as I could in real time, but would only
only perform one action per simulated timestep, which made it easy to, for instance, save an image of
one of the frames at the right time. However, my animations timing logic would need to be rewritten
to support running at different speeds or starting to animate some time after the program started.
</p>

<h3>Performance improvements <span class="atag extra">A1x-fast</span></h3>
<p class="placeholder">
	I tried to improve performance by implementing AABB culling. I represented
	them using a min and max point, generated by testing the mesh vertices. I generated
	the bounding boxes on initial scene load, but transformed them with their associated
	mesh's model matrix every frame. I performed the culling tests with the frustum in
	world space. However, my culling test did not work properly, and I would often cull
	meshes inside the frustum.
</p>

<p class="placeholder">
NOTE: you will demonstrate your performance improvements in the next section.
</p>

<h2>Performance Tests</h2>

<p class="placeholder">
This section demonstrates that you have tested your code, including finding its limits.
</p>

<p class="placeholder">
Apart from just trying my code on the different sample s72 scenes, I did not have time to test it.
</p>

<h3>Culling</h3>
<p class="placeholder">
I didn't get culling working correctly, so I don't have any scenes where it improved performance.
</p>

<h3>Bottlenecks</h3>
<p class="placeholder">
I did not have time to profile my code for bottlenecks.
</p>


<p class="placeholder">
Use graphs to demonstrate sensitivity to test scene complexity.
Include screenshots of test scenes.
</p>

<!-- For example:
<h4>CPU Bottleneck</h4>
<p class="placeholder">
The scenes <a href="#">traversal-*.s72</a> causes my viewer to bottleneck on scene traversal.
This plot shows the ...
</p>
-->

<h3>Performance Improvements</h3>

<p class="placeholder">
I did not have time to test performance improvements
</p>

<h2>Feedback</h2>
<p class="placeholder">
I enjoyed implmenting (or trying to implement) all the features in this assignment, but I wish we had more time to dedicate to profiling. Also,
while I agree that writing things like a json parser and math library are useful, given that there was already a lot to do in this assignment that's
more directly related to rendering, I think allowing us to use existing libraries for those features would've let us focus more on the rendering side.
</p>



</body></html>